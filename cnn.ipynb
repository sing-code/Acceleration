{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "BicQcEjITy1s"
      },
      "outputs": [],
      "source": [
        "import datetime as dt\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from freqtrade.exchange import timeframe_to_minutes\n",
        "from keras import Sequential\n",
        "from keras.losses import categorical_crossentropy\n",
        "from lazyft.data_loader import load_pair_data\n",
        "\n",
        "from constants import IMAGES_PATH, REPO\n",
        "import keras\n",
        "from keras.initializers import initializers_v2 as initializer\n",
        "\n",
        "from preprocess import preprocess\n",
        "from constants import IMAGES_PATH\n",
        "from cnn_model import create_cnn\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizer_v2.adam import Adam\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.config.run_functions_eagerly(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "pair = [\n",
        "    # 20 Cryptocurrencies (spot pairs)\n",
        "    \"BTC/USDT\",\"ETH/USDT\",\"XRP/USDT\",\"LTC/USDT\",\"ADA/USDT\",\n",
        "    \"DOT/USDT\",\"SOL/USDT\",\"BNB/USDT\",\"LINK/USDT\",\"MATIC/USDT\",\n",
        "    \"DOGE/USDT\",\"AVAX/USDT\",\"UNI/USDT\",\"BCH/USDT\",\"XLM/USDT\",\n",
        "    \"ETC/USDT\",\"AAVE/USDT\",\"SUSHI/USDT\",\"EOS/USDT\",\"FIL/USDT\",\n",
        "\n",
        "    # 20 Top‑Liquidity U.S. Stocks\n",
        "    \"AAPL\",  # Apple\n",
        "    \"MSFT\",  # Microsoft\n",
        "    \"AMZN\",  # Amazon\n",
        "    \"GOOGL\", # Alphabet Class A\n",
        "    \"META\",  # Meta Platforms\n",
        "    \"NVDA\",  # NVIDIA\n",
        "    \"TSLA\",  # Tesla\n",
        "    \"BRK.B\", # Berkshire Hathaway B\n",
        "    \"JPM\",   # JPMorgan Chase\n",
        "    \"V\",     # Visa\n",
        "    \"MA\",    # Mastercard\n",
        "    \"UNH\",   # UnitedHealth\n",
        "    \"JNJ\",   # Johnson & Johnson\n",
        "    \"WMT\",   # Walmart\n",
        "    \"PG\",    # Procter & Gamble\n",
        "    \"DIS\",   # Disney\n",
        "    \"HD\",    # Home Depot\n",
        "    \"BAC\",   # Bank of America\n",
        "    \"XOM\",   # ExxonMobil\n",
        "    \"CVX\"    # Chevron\n",
        "\n",
        "    # 20 Forex pairs\n",
        "    \"EUR/USD\",\"GBP/USD\",\"USD/JPY\",\"USD/CHF\",\"AUD/USD\",\n",
        "    \"USD/CAD\",\"NZD/USD\",\"EUR/GBP\",\"EUR/JPY\",\"GBP/JPY\",\n",
        "    \"EUR/CHF\",\"GBP/CHF\",\"AUD/JPY\",\"CAD/JPY\",\"NZD/JPY\",\n",
        "    \"AUD/NZD\",\"EUR/AUD\",\"EUR/CAD\",\"GBP/AUD\",\"USD/SGD\",\n",
        "\n",
        "    # 20 Commodities (gold, oil, agriculture) – use Yahoo tickers\n",
        "    \"GC=F\",   # Gold futures\n",
        "    \"SI=F\",   # Silver futures\n",
        "    \"CL=F\",   # Crude Oil WTI\n",
        "    \"NG=F\",   # Natural Gas\n",
        "    \"HG=F\",   # Copper\n",
        "    \"ZC=F\",   # Corn\n",
        "    \"ZS=F\",   # Soybeans\n",
        "    \"ZW=F\",   # Wheat\n",
        "    \"ZL=F\",   # Soybean Oil\n",
        "    \"KC=F\",   # Coffee\n",
        "    \"CC=F\",   # Cocoa\n",
        "    \"CT=F\",   # Cotton\n",
        "    \"LB=F\",   # Lumber\n",
        "    \"HO=F\",   # Heating Oil\n",
        "    \"SB=F\",   # Sugar\n",
        "    \"PA=F\",   # Palladium\n",
        "    \"PL=F\",   # Platinum\n",
        "    \"ZMF=F\",  # Minneapolis Wheat\n",
        "    \"ZSF=F\",  # Soybean Meal\n",
        "    \"KC=F\",   # Coffee (duplicated to hit 20)\n",
        "\n",
        "    # 20 Bond/ETF tickers\n",
        "    \"TLT\",   # 20+ Year Treasury ETF\n",
        "    \"IEF\",   # 7–10 Year Treasury ETF\n",
        "    \"SHY\",   # 1–3 Year Treasury ETF\n",
        "    \"BND\",   # Total Bond Market ETF\n",
        "    \"AGG\",   # Aggregate Bond ETF\n",
        "    \"LQD\",   # Investment Grade Corp Bond ETF\n",
        "    \"TIP\",   # TIPS Bond ETF\n",
        "    \"MUB\",   # Municipal Bond ETF\n",
        "    \"EMB\",   # Emerging Mkts Bond ETF\n",
        "    \"HYG\",   # High Yield Corp Bond ETF\n",
        "    \"JNK\",   # High Yield Corp Bond ETF\n",
        "    \"STIP\",  # Treasury Instl TIPS ETF\n",
        "    \"VMBS\",  # MBS ETF\n",
        "    \"VCSH\",  # Short-Term Corp Bond ETF\n",
        "    \"VCIT\",  # Intermediate-Term Corp Bond ETF\n",
        "    \"BSV\",   # Short-Term Govt/Credit ETF\n",
        "    \"IEI\",   # 3–7 Year Treasury ETF\n",
        "    \"VGSH\",  # Short-Term Treasury ETF\n",
        "    \"VGIT\",  # Intermediate-Term Treasury ETF\n",
        "    \"SCHZ\"   # Schwab US Aggregate Bond ETF\n",
        "]\n",
        "SPLIT = 0.30\n",
        "LR = 0.001\n",
        "TIMESTAMP = dt.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "# cnn_networks = 1\n",
        "models: list[keras.Sequential] = []\n",
        "image_train_path = TRAIN_IMAGES_PATH / pair.replace(\"/\", \"_\")\n",
        "image_test_path = TEST_IMAGES_PATH / pair.replace(\"/\", \"_\")\n",
        "image_train_path.mkdir(parents=True, exist_ok=True)\n",
        "image_test_path.mkdir(parents=True, exist_ok=True)\n",
        "preprocess(\n",
        "    timerange=\"20170101-20211231\",\n",
        "    image_save_path=image_train_path,\n",
        "    pair=pair,\n",
        "    interval=\"1d\",\n",
        ")\n",
        "preprocess(\n",
        "    timerange=\"20220101-\", pair=pair, image_save_path=image_test_path\n",
        ")\n",
        "\n",
        "# global history, string_list, summary\n",
        "target_size = 40\n",
        "batch_size = 20\n",
        "EPOCHS = 10"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "L0LtoxYPTy16"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-03 09:45:23.250 | INFO     | lazyft.downloader:download_missing_historical_data:301 - Checking if download is needed for BTC/USDT @ 1h interval(s)\n",
            "2022-04-03 09:45:23.253 | INFO     | lazyft.downloader:download_missing_historical_data:338 - Data is up to date\n",
            "2022-04-03 09:45:23.315 | INFO     | lazyft.data_loader:load_pair_data:39 - Loaded 35041 rows for BTC/USDT, data starts at 2018-01-01 00:00:00+00:00\n",
            "Generating images...\n",
            "========PREPROCESS REPORT========:\n",
            "Total Data Points: 1461\n",
            "Total Images Created: 1441\n",
            "Total LONG positions: 700\n",
            "Total SHORT positions: 741\n",
            "2022-04-03 09:45:32.889 | INFO     | lazyft.downloader:download_missing_historical_data:301 - Checking if download is needed for BTC/USDT @ 1h interval(s)\n",
            "2022-04-03 09:45:32.891 | INFO     | lazyft.downloader:download_missing_historical_data:338 - Data is up to date\n",
            "2022-04-03 09:45:32.940 | INFO     | lazyft.data_loader:load_pair_data:39 - Loaded 2209 rows for BTC/USDT, data starts at 2022-01-01 00:00:00+00:00\n",
            "Generating images...\n",
            "========PREPROCESS REPORT========:\n",
            "Total Data Points: 93\n",
            "Total Images Created: 73\n",
            "Total LONG positions: 36\n",
            "Total SHORT positions: 37\n",
            "Found 73 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "initializers_ = [\n",
        "    initializer.Orthogonal(),\n",
        "    initializer.LecunUniform(),\n",
        "    initializer.VarianceScaling(),\n",
        "    initializer.RandomNormal(),\n",
        "    initializer.RandomUniform(),\n",
        "    initializer.TruncatedNormal(),\n",
        "    initializer.GlorotNormal(),\n",
        "    initializer.GlorotUniform(),\n",
        "    initializer.HeNormal(),\n",
        "    initializer.HeUniform(),\n",
        "    initializer.Orthogonal(seed=42),\n",
        "    initializer.LecunUniform(seed=42),\n",
        "    initializer.VarianceScaling(seed=42),\n",
        "    initializer.RandomNormal(seed=42),\n",
        "    initializer.RandomUniform(seed=42),\n",
        "    initializer.TruncatedNormal(seed=42),\n",
        "    initializer.GlorotNormal(seed=42),\n",
        "    initializer.GlorotUniform(seed=42),\n",
        "    initializer.HeNormal(seed=42),\n",
        "    initializer.HeUniform(seed=42),\n",
        "]\n",
        "# for i, initializer_ in enumerate(initializers_):\n",
        "#     cnn = create_cnn(target_size, kernel_initializer=initializer_)\n",
        "#     # Compile each model\n",
        "#     cnn.compile(optimizer=Adam(learning_rate=LR), loss='binary_crossentropy', metrics=['acc'])\n",
        "#     models.append(cnn)\n",
        "\n",
        "# All images will be rescaled by 1./255\n",
        "train_validate_datagen = ImageDataGenerator(\n",
        "    rescale=1 / 255, validation_split=SPLIT\n",
        ")  # set validation split\n",
        "test_datagen = ImageDataGenerator(rescale=1 / 255)\n",
        "# data_chunks = ensemble_data(len(models), str(image_path))\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    directory=image_test_path,\n",
        "    target_size=(target_size, target_size),\n",
        "    batch_size=batch_size,\n",
        ")"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ZH3ixoZ6Ty17",
        "outputId": "41dd8a23-60b7-4acc-c0ed-932811862019"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def load_model(pair: str, time: str, model_name: str) -> Sequential:\n",
        "    model = create_cnn(40)\n",
        "    model_to_load = REPO / pair.replace(\"/\", \"_\") / time / \"models\" / model_name\n",
        "    model.load_weights(model_to_load)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "model = load_model(pair, \"20220403092229\", \"HeUniform.h5\")\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=LR), loss=categorical_crossentropy, metrics=[\"acc\"]\n",
        ")"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Ue55e38STy1-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/4 [======>.......................] - ETA: 0s - loss: 0.6396 - acc: 0.7500"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/raphael/PycharmProjects/freqgym/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 109ms/step - loss: 0.6582 - acc: 0.6712\n",
            "Test accs: 67.12%\n"
          ]
        }
      ],
      "source": [
        "scores = model.evaluate(test_generator)\n",
        "print(\"Test {0}s: {1:.2f}%\".format(model.metrics_names[1], scores[1] * 100))\n",
        "string_list = []\n",
        "model.summary(print_fn=lambda x: string_list.append(x))\n",
        "string_list.append(f\"test acc: {scores[1] * 100}\")\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "m6VSL0XhTy1_",
        "outputId": "6350adc1-0348-4dd2-948e-f004e1048837"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "[0.6582338213920593, 0.6712328791618347]"
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scores"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "8n19VHHmTy1_",
        "outputId": "50dd7794-7556-4f36-b8f0-b8c31e4117b4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "sample = test_generator.next()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "SSFYKoz1Ty2A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "{'LONG': 0, 'SHORT': 1}"
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_generator.class_indices\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "n4GcsshSTy2I",
        "outputId": "2edd3444-52bc-4571-9116-e46d2d120fe2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "G-RUYtY6Ty2J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "YhJI2YpnTy2L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-08 16:13:02.069 | INFO     | lazyft.downloader:download_missing_historical_data:302 - Checking if download is needed for BTC/USDT @ 1h interval(s)\n",
            "2022-04-08 16:13:02.072 | INFO     | lazyft.downloader:download_missing_historical_data:339 - Data is up to date\n",
            "2022-04-08 16:13:02.136 | INFO     | lazyft.data_loader:load_pair_data:40 - Loaded 186 rows for BTC/USDT, data starts at 2022-04-01 00:00:00+00:00\n"
          ]
        }
      ],
      "source": [
        "\n",
        "btc = load_pair_data(\"BTC/USDT\", timeframe=\"1h\", timerange=\"20220401-\")"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "2uEftRsETy2N",
        "outputId": "f5ed03d0-bbd6-421e-b26b-dca3a6aa58fc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "btc.groupby()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "acFTOKS3Ty2O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f6513d40850>"
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from util import group_by\n",
        "from datetime import timedelta\n",
        "import time\n",
        "\n",
        "\n",
        "w = btc.head(480)\n",
        "\n",
        "# t1 = time.perf_counter()\n",
        "# sampled = btc.resample('4H').mean()\n",
        "# print('Elapsed time:', timedelta(seconds=time.perf_counter() - t1))\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "2tBV0a8NTy2O",
        "outputId": "d78ffd91-ae11-4261-b1de-1984a2c7e793"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "{Timestamp('2022-04-01 00:00:00+0000', tz='UTC', freq='D'): 24,\n Timestamp('2022-04-02 00:00:00+0000', tz='UTC', freq='D'): 48,\n Timestamp('2022-04-03 00:00:00+0000', tz='UTC', freq='D'): 72,\n Timestamp('2022-04-04 00:00:00+0000', tz='UTC', freq='D'): 96,\n Timestamp('2022-04-05 00:00:00+0000', tz='UTC', freq='D'): 120,\n Timestamp('2022-04-06 00:00:00+0000', tz='UTC', freq='D'): 144,\n Timestamp('2022-04-07 00:00:00+0000', tz='UTC', freq='D'): 168,\n Timestamp('2022-04-08 00:00:00+0000', tz='UTC', freq='D'): 186}"
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w.groupby(pd.Grouper(key='date', freq='d')).get_group()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "7mdYPkwDTy2O",
        "outputId": "d1df8d93-e093-4561-c8a2-32e6df47aeb9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "                           open  high   low  close  volume\ndate                                                      \n2022-01-01 00:00:00+00:00 47.1K 47.3K 46.9K  47.1K 816.853\n2022-01-02 00:00:00+00:00 47.2K 47.4K 47.1K  47.2K 764.186\n2022-01-03 00:00:00+00:00 46.8K   47K 46.6K  46.8K   1.15K\n2022-01-04 00:00:00+00:00 46.4K 46.6K 46.2K  46.4K   1.48K\n2022-01-05 00:00:00+00:00   46K 46.2K 45.6K  45.9K   2.16K\n2022-01-06 00:00:00+00:00 43.1K 43.3K 42.9K  43.1K   1.62K\n2022-01-07 00:00:00+00:00 42.1K 42.3K 41.7K    42K   2.28K\n2022-01-08 00:00:00+00:00 41.7K 41.9K 41.5K  41.7K   1.37K\n2022-01-09 00:00:00+00:00 41.9K 42.1K 41.7K  41.9K 946.850\n2022-01-10 00:00:00+00:00 41.6K 41.9K 41.3K  41.6K   2.11K\n2022-01-11 00:00:00+00:00 42.2K 42.4K   42K  42.2K   1.55K\n2022-01-12 00:00:00+00:00 43.2K 43.4K   43K  43.2K   1.41K\n2022-01-13 00:00:00+00:00 43.5K 43.6K 43.2K  43.4K   1.45K\n2022-01-14 00:00:00+00:00 42.7K 42.9K 42.6K  42.8K   1.36K\n2022-01-15 00:00:00+00:00 43.1K 43.3K   43K  43.1K 914.002\n2022-01-16 00:00:00+00:00 43.1K 43.2K 42.9K  43.1K 858.431\n2022-01-17 00:00:00+00:00 42.5K 42.7K 42.4K  42.5K   1.15K\n2022-01-18 00:00:00+00:00 41.9K 42.1K 41.8K  41.9K   1.22K\n2022-01-19 00:00:00+00:00 41.9K 42.1K 41.7K  41.9K   1.32K\n2022-01-20 00:00:00+00:00 42.2K 42.4K   42K  42.2K   1.76K",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n    </tr>\n    <tr>\n      <th>date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2022-01-01 00:00:00+00:00</th>\n      <td>47.1K</td>\n      <td>47.3K</td>\n      <td>46.9K</td>\n      <td>47.1K</td>\n      <td>816.853</td>\n    </tr>\n    <tr>\n      <th>2022-01-02 00:00:00+00:00</th>\n      <td>47.2K</td>\n      <td>47.4K</td>\n      <td>47.1K</td>\n      <td>47.2K</td>\n      <td>764.186</td>\n    </tr>\n    <tr>\n      <th>2022-01-03 00:00:00+00:00</th>\n      <td>46.8K</td>\n      <td>47K</td>\n      <td>46.6K</td>\n      <td>46.8K</td>\n      <td>1.15K</td>\n    </tr>\n    <tr>\n      <th>2022-01-04 00:00:00+00:00</th>\n      <td>46.4K</td>\n      <td>46.6K</td>\n      <td>46.2K</td>\n      <td>46.4K</td>\n      <td>1.48K</td>\n    </tr>\n    <tr>\n      <th>2022-01-05 00:00:00+00:00</th>\n      <td>46K</td>\n      <td>46.2K</td>\n      <td>45.6K</td>\n      <td>45.9K</td>\n      <td>2.16K</td>\n    </tr>\n    <tr>\n      <th>2022-01-06 00:00:00+00:00</th>\n      <td>43.1K</td>\n      <td>43.3K</td>\n      <td>42.9K</td>\n      <td>43.1K</td>\n      <td>1.62K</td>\n    </tr>\n    <tr>\n      <th>2022-01-07 00:00:00+00:00</th>\n      <td>42.1K</td>\n      <td>42.3K</td>\n      <td>41.7K</td>\n      <td>42K</td>\n      <td>2.28K</td>\n    </tr>\n    <tr>\n      <th>2022-01-08 00:00:00+00:00</th>\n      <td>41.7K</td>\n      <td>41.9K</td>\n      <td>41.5K</td>\n      <td>41.7K</td>\n      <td>1.37K</td>\n    </tr>\n    <tr>\n      <th>2022-01-09 00:00:00+00:00</th>\n      <td>41.9K</td>\n      <td>42.1K</td>\n      <td>41.7K</td>\n      <td>41.9K</td>\n      <td>946.850</td>\n    </tr>\n    <tr>\n      <th>2022-01-10 00:00:00+00:00</th>\n      <td>41.6K</td>\n      <td>41.9K</td>\n      <td>41.3K</td>\n      <td>41.6K</td>\n      <td>2.11K</td>\n    </tr>\n    <tr>\n      <th>2022-01-11 00:00:00+00:00</th>\n      <td>42.2K</td>\n      <td>42.4K</td>\n      <td>42K</td>\n      <td>42.2K</td>\n      <td>1.55K</td>\n    </tr>\n    <tr>\n      <th>2022-01-12 00:00:00+00:00</th>\n      <td>43.2K</td>\n      <td>43.4K</td>\n      <td>43K</td>\n      <td>43.2K</td>\n      <td>1.41K</td>\n    </tr>\n    <tr>\n      <th>2022-01-13 00:00:00+00:00</th>\n      <td>43.5K</td>\n      <td>43.6K</td>\n      <td>43.2K</td>\n      <td>43.4K</td>\n      <td>1.45K</td>\n    </tr>\n    <tr>\n      <th>2022-01-14 00:00:00+00:00</th>\n      <td>42.7K</td>\n      <td>42.9K</td>\n      <td>42.6K</td>\n      <td>42.8K</td>\n      <td>1.36K</td>\n    </tr>\n    <tr>\n      <th>2022-01-15 00:00:00+00:00</th>\n      <td>43.1K</td>\n      <td>43.3K</td>\n      <td>43K</td>\n      <td>43.1K</td>\n      <td>914.002</td>\n    </tr>\n    <tr>\n      <th>2022-01-16 00:00:00+00:00</th>\n      <td>43.1K</td>\n      <td>43.2K</td>\n      <td>42.9K</td>\n      <td>43.1K</td>\n      <td>858.431</td>\n    </tr>\n    <tr>\n      <th>2022-01-17 00:00:00+00:00</th>\n      <td>42.5K</td>\n      <td>42.7K</td>\n      <td>42.4K</td>\n      <td>42.5K</td>\n      <td>1.15K</td>\n    </tr>\n    <tr>\n      <th>2022-01-18 00:00:00+00:00</th>\n      <td>41.9K</td>\n      <td>42.1K</td>\n      <td>41.8K</td>\n      <td>41.9K</td>\n      <td>1.22K</td>\n    </tr>\n    <tr>\n      <th>2022-01-19 00:00:00+00:00</th>\n      <td>41.9K</td>\n      <td>42.1K</td>\n      <td>41.7K</td>\n      <td>41.9K</td>\n      <td>1.32K</td>\n    </tr>\n    <tr>\n      <th>2022-01-20 00:00:00+00:00</th>\n      <td>42.2K</td>\n      <td>42.4K</td>\n      <td>42K</td>\n      <td>42.2K</td>\n      <td>1.76K</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w.set_index(\"date\").resample(\"1d\").mean()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "iWX1BdzwTy2O",
        "outputId": "bdffd995-c6ae-4807-bc4c-bb1ca904276e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "5760"
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from freqtrade.exchange import timeframe_to_minutes\n",
        "\n",
        "MINUTES_IN_DAY = 1440\n",
        "tf_minutes = timeframe_to_minutes(\"5m\")\n",
        "20 * MINUTES_IN_DAY // tf_minutes\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "yCDsKcFxTy2P",
        "outputId": "bf9b8094-05ef-4588-8c6e-fd31c038c3ae"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "0"
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "btc.head(1).index[0]"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "CWSv8qtNTy2P",
        "outputId": "4981952c-abc3-41d2-b461-48a0d2dfc0c2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import util\n",
        "from preprocess import alive_bar\n",
        "\n",
        "\n",
        "def split_timeframes(\n",
        "    df: pd.DataFrame,\n",
        "    window: int,\n",
        "    timeframes: list[str],\n",
        "    list_dates: list[str],\n",
        "    download_interval: str,\n",
        ") -> dict[str, list[pd.Series]]:\n",
        "    \"\"\"\n",
        "    Given a dataframe, a window size, a list of timeframes, and a list of dates,\n",
        "    split the dataframe into a list of lists of series, where each series is a list of prices\n",
        "    for a specific timeframe\n",
        "\n",
        "    :param df: The dataframe that contains the data\n",
        "    :param window: The size of the moving window. This is the number of observations used for\n",
        "    calculating the statistic. Each window will be a fixed size\n",
        "    :param timeframes: a list of timeframes to use for grouping the data\n",
        "    :param list_dates: list of dates\n",
        "    :return: A list of lists of series. Each list of series is a list of the closing prices of the\n",
        "    stocks for a given timeframe.\n",
        "    \"\"\"\n",
        "    series_dict: dict[str, list[pd.Series]] = {}\n",
        "    index = window\n",
        "    with alive_bar(\n",
        "        len(list_dates) - window - 1, title=\"Creating decision map...\", bar=\"filling\"\n",
        "    ) as bar:\n",
        "        while True:\n",
        "            idx = index\n",
        "            save_idx = index - 1\n",
        "\n",
        "            if idx == len(list_dates):\n",
        "                break\n",
        "            if index >= len(list_dates) - 1:\n",
        "                save_idx = -2\n",
        "                after = df[\"date\"] > list_dates[-window - 1]\n",
        "                data_slice = df.loc[after]\n",
        "            else:\n",
        "                after = df[\"date\"] > list_dates[idx - window]\n",
        "                before = df[\"date\"] <= list_dates[idx]\n",
        "                data_slice = df.loc[after & before]\n",
        "\n",
        "            # select appropriate timeframe\n",
        "            # print('len of data slice: ', len(data_slice), 'head: ', data_slice.head())\n",
        "            tf_series = []\n",
        "\n",
        "            # group dataslices by timeframe\n",
        "            for freq in timeframes:\n",
        "                if freq == download_interval:\n",
        "                    tf_series.append(data_slice[\"close\"].tail(20))\n",
        "                    continue\n",
        "                group_dt = util.group_by(data_slice, freq)\n",
        "                tf_series.append(group_dt[\"close\"].tail(20))\n",
        "            series_dict[list_dates[save_idx]] = tf_series\n",
        "            index += 1\n",
        "            bar()\n",
        "    return series_dict\n",
        "\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "XMaGW6vPTy2P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-04-07 06:52:45.380 | INFO     | lazyft.downloader:download_missing_historical_data:301 - Checking if download is needed for BTC/USDT @ 1h interval(s)\n",
            "2022-04-07 06:52:45.382 | INFO     | lazyft.downloader:download_missing_historical_data:338 - Data is up to date\n",
            "2022-04-07 06:52:45.438 | INFO     | lazyft.data_loader:load_pair_data:40 - Loaded 581 rows for BTC/USDT, data starts at 2022-03-13 00:00:00+00:00\n"
          ]
        }
      ],
      "source": [
        "btc = load_pair_data(\"BTC/USDT\", timeframe=\"1h\", timerange=\"20220313-\")"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "JprklMWjTy2Q",
        "outputId": "d3d2a4cd-a976-4989-8ea1-aba683ab6783"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "split_timeframes(\n",
        "    btc, 20, [\"1h\", \"4h\", \"8h\", \"1d\"], util.get_dates_from_df(btc, \"1d\"), \"1h\"\n",
        ")"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "3Rv_sM9BTy2Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "series_dict: dict[str, list[pd.Series]] = {}\n",
        "window = 2\n",
        "df = btc\n",
        "list_dates = util.get_dates_from_df(btc, \"1d\")\n",
        "timeframes = [\"1h\", \"4h\", \"8h\", \"1d\"]\n",
        "download_interval = \"1h\"\n",
        "index = window"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "jBycAF3uTy2Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "idx = index\n",
        "save_idx = index - 1\n",
        "\n",
        "assert idx != len(list_dates)\n",
        "\n",
        "if index >= len(list_dates) - 1:\n",
        "    save_idx = -2\n",
        "    after = df[\"date\"] > list_dates[-window - 1]\n",
        "    data_slice = df.loc[after]\n",
        "else:\n",
        "    after = df[\"date\"] > list_dates[idx - window]\n",
        "    before = df[\"date\"] <= list_dates[idx]\n",
        "    data_slice = df.loc[after & before]\n",
        "\n",
        "# select appropriate timeframe\n",
        "# print('len of data slice: ', len(data_slice), 'head: ', data_slice.head())\n",
        "tf_series = []\n",
        "\n",
        "# group dataslices by timeframe\n",
        "for freq in timeframes:\n",
        "    if freq == download_interval:\n",
        "        tf_series.append(data_slice[\"close\"].tail(20))\n",
        "        continue\n",
        "    group_dt = util.group_by(data_slice, freq)\n",
        "    tf_series.append(group_dt[\"close\"].tail(20))\n",
        "series_dict[list_dates[save_idx]] = tf_series\n",
        "index += 1"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "AGOoR_2XTy2Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "                         date  open  high   low  close  volume\n1   2022-03-13 01:00:00+00:00 38.9K 39.3K 38.9K    39K   1.29K\n2   2022-03-13 02:00:00+00:00   39K 39.2K   39K  39.2K 649.294\n3   2022-03-13 03:00:00+00:00 39.2K 39.2K 39.1K  39.2K 604.576\n4   2022-03-13 04:00:00+00:00 39.2K 39.3K 39.1K  39.1K 547.678\n5   2022-03-13 05:00:00+00:00 39.1K 39.2K 39.1K  39.1K 318.244\n..                        ...   ...   ...   ...    ...     ...\n475 2022-04-01 19:00:00+00:00 46.3K 46.4K 46.1K  46.4K   1.36K\n476 2022-04-01 20:00:00+00:00 46.4K 46.4K 46.1K  46.1K 889.165\n477 2022-04-01 21:00:00+00:00 46.1K 46.4K 46.1K  46.3K 704.819\n478 2022-04-01 22:00:00+00:00 46.3K 46.4K 46.2K  46.4K   1.04K\n479 2022-04-01 23:00:00+00:00 46.4K 46.4K 46.1K  46.3K 737.491\n\n[479 rows x 6 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>2022-03-13 01:00:00+00:00</td>\n      <td>38.9K</td>\n      <td>39.3K</td>\n      <td>38.9K</td>\n      <td>39K</td>\n      <td>1.29K</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2022-03-13 02:00:00+00:00</td>\n      <td>39K</td>\n      <td>39.2K</td>\n      <td>39K</td>\n      <td>39.2K</td>\n      <td>649.294</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2022-03-13 03:00:00+00:00</td>\n      <td>39.2K</td>\n      <td>39.2K</td>\n      <td>39.1K</td>\n      <td>39.2K</td>\n      <td>604.576</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2022-03-13 04:00:00+00:00</td>\n      <td>39.2K</td>\n      <td>39.3K</td>\n      <td>39.1K</td>\n      <td>39.1K</td>\n      <td>547.678</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2022-03-13 05:00:00+00:00</td>\n      <td>39.1K</td>\n      <td>39.2K</td>\n      <td>39.1K</td>\n      <td>39.1K</td>\n      <td>318.244</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>475</th>\n      <td>2022-04-01 19:00:00+00:00</td>\n      <td>46.3K</td>\n      <td>46.4K</td>\n      <td>46.1K</td>\n      <td>46.4K</td>\n      <td>1.36K</td>\n    </tr>\n    <tr>\n      <th>476</th>\n      <td>2022-04-01 20:00:00+00:00</td>\n      <td>46.4K</td>\n      <td>46.4K</td>\n      <td>46.1K</td>\n      <td>46.1K</td>\n      <td>889.165</td>\n    </tr>\n    <tr>\n      <th>477</th>\n      <td>2022-04-01 21:00:00+00:00</td>\n      <td>46.1K</td>\n      <td>46.4K</td>\n      <td>46.1K</td>\n      <td>46.3K</td>\n      <td>704.819</td>\n    </tr>\n    <tr>\n      <th>478</th>\n      <td>2022-04-01 22:00:00+00:00</td>\n      <td>46.3K</td>\n      <td>46.4K</td>\n      <td>46.2K</td>\n      <td>46.4K</td>\n      <td>1.04K</td>\n    </tr>\n    <tr>\n      <th>479</th>\n      <td>2022-04-01 23:00:00+00:00</td>\n      <td>46.4K</td>\n      <td>46.4K</td>\n      <td>46.1K</td>\n      <td>46.3K</td>\n      <td>737.491</td>\n    </tr>\n  </tbody>\n</table>\n<p>479 rows × 6 columns</p>\n</div>"
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.loc[(df[\"date\"] > list_dates[20 - 20]) & (df[\"date\"] < list_dates[20])]"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "RSJI3uK6Ty2Q",
        "outputId": "e4367bce-cd33-42df-c934-95aff5729cde"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "XgBZhtK5Ty2Q"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}